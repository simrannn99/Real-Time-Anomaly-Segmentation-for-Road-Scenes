Net(
  (initial): InitialBlock(
    (conv): ConvBNAct(
      (0): Conv2d(3, 13, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Activation(
        (activation): PReLU(num_parameters=1)
      )
    )
    (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  )
  (bottleneck1): BottleNeck1(
    (conv_pool): Bottleneck(
      (left_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (left_conv): ConvBNAct(
        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Activation(
          (activation): ReLU()
        )
      )
      (right_init_conv): Sequential(
        (0): ConvBNAct(
          (0): Conv2d(16, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Activation(
            (activation): ReLU()
          )
        )
        (1): ConvBNAct(
          (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Activation(
            (activation): ReLU()
          )
        )
      )
      (right_last_conv): Sequential(
        (0): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): Dropout(p=0.01, inplace=False)
      )
      (act): Activation(
        (activation): PReLU(num_parameters=1)
      )
    )
    (conv_regular): Sequential(
      (0): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.01, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
      (1): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.01, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
      (2): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.01, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
      (3): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.01, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
    )
  )
  (bottleneck2): BottleNeck23(
    (conv_pool): Bottleneck(
      (left_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (left_conv): ConvBNAct(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Activation(
          (activation): ReLU()
        )
      )
      (right_init_conv): Sequential(
        (0): ConvBNAct(
          (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Activation(
            (activation): ReLU()
          )
        )
        (1): ConvBNAct(
          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Activation(
            (activation): ReLU()
          )
        )
      )
      (right_last_conv): Sequential(
        (0): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): Dropout(p=0.1, inplace=False)
      )
      (act): Activation(
        (activation): PReLU(num_parameters=1)
      )
    )
    (conv_regular): Sequential(
      (0): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.1, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
      (1): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.1, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
      (2): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (2): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.1, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
      (3): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.1, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
      (4): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.1, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
      (5): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.1, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
      (6): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (2): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.1, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
      (7): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.1, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
    )
  )
  (bottleneck3): BottleNeck23(
    (conv_regular): Sequential(
      (0): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.1, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
      (1): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.1, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
      (2): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (2): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.1, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
      (3): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.1, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
      (4): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.1, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
      (5): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.1, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
      (6): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (2): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.1, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
      (7): Bottleneck(
        (right_init_conv): Sequential(
          (0): ConvBNAct(
            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
          (1): ConvBNAct(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Activation(
              (activation): ReLU()
            )
          )
        )
        (right_last_conv): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Dropout(p=0.1, inplace=False)
        )
        (act): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
    )
  )
  (bottleneck4): BottleNeck45(
    (conv_unpool): Bottleneck(
      (left_conv): ConvBNAct(
        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Activation(
          (activation): ReLU()
        )
      )
      (left_pool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))
      (right_init_conv): Sequential(
        (0): ConvBNAct(
          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Activation(
            (activation): ReLU()
          )
        )
        (1): Upsample(
          (up_conv): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
        )
      )
      (right_last_conv): Sequential(
        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): Dropout(p=0.1, inplace=False)
      )
      (act): Activation(
        (activation): PReLU(num_parameters=1)
      )
    )
    (conv_regular): Bottleneck(
      (right_init_conv): Sequential(
        (0): ConvBNAct(
          (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Activation(
            (activation): ReLU()
          )
        )
        (1): ConvBNAct(
          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Activation(
            (activation): ReLU()
          )
        )
      )
      (right_last_conv): Sequential(
        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): Dropout(p=0.1, inplace=False)
      )
      (act): Activation(
        (activation): PReLU(num_parameters=1)
      )
    )
    (conv_extra): Bottleneck(
      (right_init_conv): Sequential(
        (0): ConvBNAct(
          (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Activation(
            (activation): ReLU()
          )
        )
        (1): ConvBNAct(
          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Activation(
            (activation): ReLU()
          )
        )
      )
      (right_last_conv): Sequential(
        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): Dropout(p=0.1, inplace=False)
      )
      (act): Activation(
        (activation): PReLU(num_parameters=1)
      )
    )
  )
  (bottleneck5): BottleNeck45(
    (conv_unpool): Bottleneck(
      (left_conv): ConvBNAct(
        (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Activation(
          (activation): ReLU()
        )
      )
      (left_pool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))
      (right_init_conv): Sequential(
        (0): ConvBNAct(
          (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Activation(
            (activation): ReLU()
          )
        )
        (1): Upsample(
          (up_conv): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
        )
      )
      (right_last_conv): Sequential(
        (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): Dropout(p=0.1, inplace=False)
      )
      (act): Activation(
        (activation): PReLU(num_parameters=1)
      )
    )
    (conv_regular): Bottleneck(
      (right_init_conv): Sequential(
        (0): ConvBNAct(
          (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Activation(
            (activation): ReLU()
          )
        )
        (1): ConvBNAct(
          (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Activation(
            (activation): ReLU()
          )
        )
      )
      (right_last_conv): Sequential(
        (0): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): Dropout(p=0.1, inplace=False)
      )
      (act): Activation(
        (activation): PReLU(num_parameters=1)
      )
    )
  )
  (fullconv): Upsample(
    (up_conv): Sequential(
      (0): ConvBNAct(
        (0): Conv2d(16, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Activation(
          (activation): PReLU(num_parameters=1)
        )
      )
      (1): Upsample(scale_factor=2.0, mode='bilinear')
    )
  )
)